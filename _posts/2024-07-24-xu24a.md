---
title: 'From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning
  for Balanced Clinical Predictions on EHR'
abstract: Electronic Health Records (EHRs) contain rich patient information and are
  crucial for clinical research and practice.  In recent years, deep learning models
  have been applied to EHRs, but they often rely on massive features, which may not
  be readily available for all patients. We propose \ours{}\footnote{Short for \textbf{H}ypergraph
  \textbf{T}ransformer \textbf{P}retrain-then-Finetuning with \textbf{S}moo\textbf{t}hness-induced
  regularization \textbf{a}nd \textbf{R}eweighting.}, which leverages hypergraph structures
  with a pretrain-then-finetune framework for modeling EHR data, enabling seamless
  integration of additional features.  Additionally, we design two techniques, namely
  (1) \emph{Smoothness-inducing Regularization} and (2) \emph{Group-balanced Reweighting},
  to enhance the modelâ€™s robustness during finetuning. Through experiments conducted
  on two real EHR datasets, we demonstrate that \ours{} consistently outperforms va
year: '2024'
volume: '248'
publisher: PMLR
series: Proceedings of Machine Learning Research
software: https://github.com/ritaranx/HTP-Star
layout: inproceedings
issn: 2640-3498
id: xu24a
month: 0
tex_title: 'From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning
  for Balanced Clinical Predictions on EHR'
firstpage: 182
lastpage: 197
page: 182-197
order: 182
cycles: false
bibtex_author: Xu, Ran and Lu, Yiwen and Liu, Chang and Chen, Yong and Sun, Yan and
  Hu, Xiao and Ho, Joyce C and Yang, Carl
author:
- given: Ran
  family: Xu
- given: Yiwen
  family: Lu
- given: Chang
  family: Liu
- given: Yong
  family: Chen
- given: Yan
  family: Sun
- given: Xiao
  family: Hu
- given: Joyce C
  family: Ho
- given: Carl
  family: Yang
date: 2024-07-24
address:
container-title: Proceedings of the fifth Conference on Health, Inference, and Learning
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 24
pdf: https://raw.githubusercontent.com/mlresearch/v248/main/assets/xu24a/xu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
